{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI Models for Engine Data ðŸ“Š**"
      ],
      "metadata": {
        "id": "mBKPwPImn0sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Engine Data Preprocessing"
      ],
      "metadata": {
        "id": "Z0UIRiWAyyZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Assume the dataset is in a CSV file\n",
        "df = pd.read_csv('/content/engine_data.csv')\n",
        "\n",
        "# Reshape the data so that each car has its own row\n",
        "df_pivot = df.pivot_table(index='Car ID',\n",
        "                          columns=df.groupby('Car ID').cumcount() + 1,  # Use cumcount to get a numerical reading starting from 1\n",
        "                          values=['Engine rpm', 'Lub oil pressure', 'Fuel pressure', 'Coolant pressure', 'lub oil temp', 'Coolant temp'],\n",
        "                          aggfunc='first')\n",
        "\n",
        "# Rename the columns in the format: FeatureR1, FeatureR2, ...\n",
        "df_pivot.columns = [f'{col[0]}R{col[1]}' for col in df_pivot.columns]\n",
        "\n",
        "# Arrange the columns in the desired order\n",
        "columns = []\n",
        "for i in range(1, 11):  # To cover 10 readings (from R1 to R10)\n",
        "    columns.extend([f'Engine rpmR{i}', f'Lub oil pressureR{i}', f'Fuel pressureR{i}', f'Coolant pressureR{i}',\n",
        "                    f'Lub oil tempR{i}', f'Coolant tempR{i}'])\n",
        "\n",
        "# Check existing columns and filter out any missing ones\n",
        "existing_columns = [col for col in columns if col in df_pivot.columns]\n",
        "df_pivot = df_pivot[existing_columns]\n",
        "\n",
        "# Add the \"Label\" column from the last row of each \"Car ID\"\n",
        "df_labels = df.groupby('Car ID').last()[['Label']]  # Get the label from the last row for each Car ID\n",
        "\n",
        "# Merge the reshaped data with the \"Label\"\n",
        "df_pivot = df_pivot.merge(df_labels, on='Car ID', how='left')\n",
        "\n",
        "# Save the result to a new CSV file\n",
        "df_pivot.to_csv('transformed_dataset_2.csv', index=True)\n",
        "\n",
        "# Display the result\n",
        "print(df_pivot.head())\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/transformed_dataset_2.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop the row with missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Drop 'Car ID' column as it's not useful\n",
        "df = df.drop(columns=['Car ID'])\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "feature_columns = df.columns[:-1]  # All columns except 'Label'\n",
        "df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
        "\n",
        "# Address class imbalance using SMOTE\n",
        "X = df[feature_columns]\n",
        "y = df['Label']\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Create balanced dataframe\n",
        "df_balanced = pd.DataFrame(X_resampled, columns=feature_columns)\n",
        "df_balanced['Label'] = y_resampled\n",
        "\n",
        "# Shuffle the dataset\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save the preprocessed dataset\n",
        "df_balanced.to_csv(\"preprocessed_car_engine_data.csv\", index=False)\n",
        "\n",
        "print(\"Preprocessing complete with SMOTE applied and data shuffled. Preprocessed dataset saved as 'preprocessed_car_engine_data.csv'.\")"
      ],
      "metadata": {
        "id": "aOEdAilSnydD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBOOST Model - Engine Data"
      ],
      "metadata": {
        "id": "ZlTDmY21figZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"preprocessed_car_engine_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['Label', 'Car ID'])  # Exclude 'Car ID' if not useful\n",
        "y = df['Label']\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Convert data to DMatrix format for XGBoost\n",
        "train_dmatrix = xgb.DMatrix(X_train, label=y_train)\n",
        "val_dmatrix = xgb.DMatrix(X_val, label=y_val)\n",
        "test_dmatrix = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Set XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'multi:softmax',  # Multi-class classification\n",
        "    'num_class': len(np.unique(y)),\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'eta': 0.1,\n",
        "    'max_depth': 6,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "watchlist = [(train_dmatrix, 'train'), (val_dmatrix, 'eval')]\n",
        "model = xgb.train(params, train_dmatrix, num_boost_round=100, evals=watchlist, early_stopping_rounds=10)\n",
        "\n",
        "# Make predictions\n",
        "preds = model.predict(test_dmatrix)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print('Classification Report:\\n', classification_report(y_test, preds))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(confusion_matrix(y_test, preds), annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance\n",
        "xgb.plot_importance(model)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QIne7T7xfh94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANN Model - Engine Data"
      ],
      "metadata": {
        "id": "x17gsOQ-gfiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the new dataset\n",
        "new_file_path = \"/content/preprocessed_car_engine_data.csv\"\n",
        "df_new = pd.read_csv(new_file_path)\n",
        "\n",
        "# Display the first few rows to inspect the structure\n",
        "df_new.head()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Separate features and target\n",
        "X_new = df_new.drop(columns=['Label'])  # Feature columns\n",
        "y_new = df_new['Label']  # Target column\n",
        "\n",
        "# Split data into train (70%), validation (15%), and test (15%)\n",
        "X_train_new, X_temp_new, y_train_new, y_temp_new = train_test_split(\n",
        "    X_new, y_new, test_size=0.3, random_state=42, stratify=y_new\n",
        ")\n",
        "X_val_new, X_test_new, y_val_new, y_test_new = train_test_split(\n",
        "    X_temp_new, y_temp_new, test_size=0.5, random_state=42, stratify=y_temp_new\n",
        ")\n",
        "\n",
        "# Check dataset sizes\n",
        "X_train_new.shape, X_val_new.shape, X_test_new.shape\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Define the ANN model\n",
        "model_new = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(50,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(len(y_new.unique()), activation='softmax')  # Assuming classification with multiple classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_new.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history_new = model_new.fit(\n",
        "    X_train_new, y_train_new,\n",
        "    validation_data=(X_val_new, y_val_new),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss_new, test_accuracy_new = model_new.evaluate(X_test_new, y_test_new, verbose=1)\n",
        "print(f'Test Accuracy: {test_accuracy_new:.4f}')\n",
        "\n",
        "# Visualization of training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_new.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history_new.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_new.history['loss'], label='Train Loss')\n",
        "plt.plot(history_new.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred_new = np.argmax(model_new.predict(X_test_new), axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_new, y_pred_new))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix_new = confusion_matrix(y_test_new, y_pred_new)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_new, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_new), yticklabels=np.unique(y_new))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "print(\"Model Summary:\")\n",
        "model_new.summary()"
      ],
      "metadata": {
        "id": "LK7Vo0QOhN-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bagging Model - Engine Data"
      ],
      "metadata": {
        "id": "yDvAx2pFj09r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib  # Library for saving and loading models\n",
        "import sklearn  # To check the scikit-learn version\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# âœ… Fixing the __sklearn_tags__ issue in the latest version\n",
        "if not hasattr(sklearn.base.ClassifierMixin, \"__sklearn_tags__\"):\n",
        "    sklearn.base.ClassifierMixin.__sklearn_tags__ = lambda self: {}\n",
        "\n",
        "# âœ… Print the current scikit-learn version for compatibility\n",
        "print(f\"Using scikit-learn version: {sklearn.__version__}\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/preprocessed_car_engine_data.csv')\n",
        "\n",
        "# Fix column names\n",
        "df.columns = df.columns.str.replace(' ', '_')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=['Label'])\n",
        "y = df['Label']\n",
        "\n",
        "# Split data: 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize base models\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "xgb_model = XGBClassifier(random_state=42, n_jobs=-1)\n",
        "lgb_model = LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
        "\n",
        "# âœ… Create BaggingClassifier using estimator instead of base_estimator\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=rf_model,  # âœ… Using RandomForest as base model\n",
        "    n_estimators=10,  # Number of models inside Bagging\n",
        "    bootstrap=True,  # âœ… Enable bootstrapping to increase variance\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# âœ… Train the model on training data\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# âœ… Save the model with the current scikit-learn version\n",
        "joblib.dump(bagging_clf, \"bagging_model.pkl\")\n",
        "print(\"âœ… Model saved successfully as bagging_model.pkl\")\n",
        "\n",
        "# âœ… Evaluate on validation set\n",
        "y_val_pred = bagging_clf.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f'Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "# âœ… Evaluate on test set\n",
        "y_test_pred = bagging_clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# âœ… Print confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# âœ… Print classification report\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "test_mean = np.mean(test_scores, axis=1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')\n",
        "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Validation Score')\n",
        "\n",
        "plt.xlabel('Training Examples')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Curve')\n",
        "\n",
        "# Adjust the Y-axis scale to make the differences more visible\n",
        "plt.ylim([0.0, 1.01])  # Change the Y-axis range to better highlight differences\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for i, class_label in enumerate(np.unique(y)):\n",
        "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'Class {class_label} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve (One-vs-Rest)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "crO-_MG8jx5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Model - Engine Data"
      ],
      "metadata": {
        "id": "E21xhtaNkU6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Load data\n",
        "file_path = \"/content/preprocessed_car_engine_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[\"Label\"])  # Features\n",
        "y = df[\"Label\"]  # Target variable\n",
        "\n",
        "# Split data into 70% training and 30% validation + test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Split remaining 30% into 15% validation and 15% test\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Create Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation data\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "# Evaluate model on validation data\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model on test data\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_report = classification_report(y_test, y_test_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", class_report)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1], yticklabels=[0, 1])\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Actual Values\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8T8IYIKMkObG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}