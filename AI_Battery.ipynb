{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI Models for Battery Data ðŸ“Š**"
      ],
      "metadata": {
        "id": "7KewF9QizyAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Battery Preproccesing\n"
      ],
      "metadata": {
        "id": "uY06jEUEki68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"data in row.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['N#', 'CarID'])\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['Label'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "feature_columns = df.columns[:-1]  # All columns except 'Label'\n",
        "df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(df[feature_columns], df['Label'])\n",
        "\n",
        "df_resampled = pd.DataFrame(X_resampled, columns=feature_columns)\n",
        "df_resampled['Label'] = y_resampled\n",
        "\n",
        "# Save the preprocessed dataset\n",
        "df_resampled.to_csv(\"preprocessed_battery_data.csv\", index=False)\n",
        "\n",
        "print(\"Preprocessing complete with SMOTE applied. Preprocessed dataset saved as 'preprocessed_battery_data.csv'.\")\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def shuffle_csv(input_file, output_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # Shuffle the DataFrame\n",
        "    df = df.sample(frac=1, random_state=random.randint(1, 10000)).reset_index(drop=True)\n",
        "\n",
        "    # Save the shuffled data to a new CSV file\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "    print(f\"Shuffled data saved to: {output_path}\")\n",
        "\n",
        "# Define file paths\n",
        "input_file = \"/content/preprocessed_battery_data.csv\"\n",
        "output_file = \"/content/shuffled_battery_data.csv\"\n",
        "\n",
        "# Shuffle and save the data\n",
        "shuffle_csv(input_file, output_file)"
      ],
      "metadata": {
        "id": "4SP20m2vlwRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBOOST Model - Battery Data"
      ],
      "metadata": {
        "id": "GKNH-Q2Klw3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install xgboost scikit-learn pandas matplotlib seaborn\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "file_path = \"shuffled_battery_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display dataset preview\n",
        "print(\"Dataset preview:\")\n",
        "display(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in dataset:\\n\", df.isnull().sum())\n",
        "\n",
        "# Display column names\n",
        "print(\"Column names in dataset:\", df.columns)\n",
        "\n",
        "# Identify the correct target column\n",
        "target_column = \"Label\"  # This is your target column\n",
        "\n",
        "# Define X (features) and y (target)\n",
        "X = df.drop(columns=[target_column])  # Features\n",
        "y = df[target_column]  # Target variable\n",
        "\n",
        "# Split the data into Train (70%), Validation (15%), Test (15%) using correct stratification\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Check dataset sizes\n",
        "print(f\"Train size: {X_train.shape[0]}, Validation size: {X_val.shape[0]}, Test size: {X_test.shape[0]}\")\n",
        "\n",
        "# Convert data into XGBoost's DMatrix format (for optimization)\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Define XGBoost parameters for classification\n",
        "params = {\n",
        "    'objective': 'multi:softmax',  # Use 'binary:logistic' for binary classification\n",
        "    'num_class': len(np.unique(y)),  # Number of classes\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'learning_rate': 0.1,\n",
        "    'max_depth': 6,\n",
        "    'n_estimators': 100,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Train the XGBoost model\n",
        "model = xgb.train(params, dtrain, num_boost_round=100, evals=[(dval, \"Validation\")], early_stopping_rounds=10, verbose_eval=10)\n",
        "\n",
        "# Predictions on validation and test sets\n",
        "y_val_pred = model.predict(dval)\n",
        "y_test_pred = model.predict(dtest)\n",
        "\n",
        "# Convert predictions to integer labels (if needed)\n",
        "y_val_pred = y_val_pred.astype(int)\n",
        "y_test_pred = y_test_pred.astype(int)\n",
        "\n",
        "# Evaluate performance\n",
        "def evaluate_classification(y_true, y_pred, dataset_name):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\nPerformance on {dataset_name}:\")\n",
        "    print(f\"Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
        "\n",
        "# Evaluate model on validation and test sets\n",
        "evaluate_classification(y_val, y_val_pred, \"Validation Set\")\n",
        "evaluate_classification(y_test, y_test_pred, \"Test Set\")\n",
        "\n",
        "# Confusion matrix visualization\n",
        "def plot_confusion_matrix(y_true, y_pred, dataset_name):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_true), yticklabels=np.unique(y_true))\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(f\"Confusion Matrix - {dataset_name}\")\n",
        "    plt.show()\n",
        "\n",
        "# Plot confusion matrices\n",
        "plot_confusion_matrix(y_val, y_val_pred, \"Validation Set\")\n",
        "plot_confusion_matrix(y_test, y_test_pred, \"Test Set\")\n",
        "\n",
        "# Feature importance plot\n",
        "xgb.plot_importance(model)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "45A6LdBMlSSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ANN Model - Battery Data"
      ],
      "metadata": {
        "id": "gI6-PExSlNbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIihBYUUkdYH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/shuffled_battery_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows to inspect the structure\n",
        "df.head()\n",
        "\n",
        "#------------------------------------------------------\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['Label'])  # Feature columns\n",
        "y = df['Label']  # Target column\n",
        "\n",
        "# Split data into train (70%), validation (15%), and test (15%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Check dataset sizes\n",
        "X_train.shape, X_val.shape, X_test.shape\n",
        "\n",
        "#-----------------------------------------------------\n",
        "\n",
        "# Define the ANN model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(40,)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(len(y.unique()), activation='softmax')  # Assuming classification with multiple classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=25,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Visualization of training history\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "print(\"Model Summary:\")\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Model - Battery Data"
      ],
      "metadata": {
        "id": "_Fw_r29AsP-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib  # Library for saving and loading the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/shuffled_battery_data.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first 5 rows to inspect the data\n",
        "print(df.head())\n",
        "\n",
        "# Check columns and ensure there are no missing values\n",
        "print(df.info())\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Define features and target variable\n",
        "X = df.drop(columns=['Label'])  # Specify the target column name\n",
        "y = df['Label']  # Specify the target column name\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "model_filename = \"random_forest_model.pkl\"\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"Model saved as {model_filename}\")\n",
        "\n",
        "# Load the model for testing\n",
        "loaded_model = joblib.load(model_filename)\n",
        "\n",
        "# Make predictions on the test set using the loaded model\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.imshow(conf_matrix, cmap='Blues', interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')\n",
        "plt.plot(train_sizes, test_mean, 'o-', color='green', label='Validation Score')\n",
        "\n",
        "plt.xlabel('Training Examples')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Curve')\n",
        "\n",
        "# Adjust the Y-axis scale to make the differences more visible\n",
        "plt.ylim([0.90, 1.001])  # Set the Y-axis range to be closer\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Convert y_test to binarized format (One-vs-Rest)\n",
        "y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
        "y_prob = loaded_model.predict_proba(X_test)  # Classification probabilities for each class\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot ROC Curve for each class individually\n",
        "for i, class_label in enumerate(np.unique(y)):\n",
        "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'Class {class_label} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot the random guessing line (baseline)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyXo7zbEsNYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}